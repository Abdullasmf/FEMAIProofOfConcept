{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from urllib.request import urlretrieve\n",
    "#import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import nbformat\n",
    "#sns.set_style('darkgrid')\n",
    "#matplotlib.rcParams['font.size'] = 14\n",
    "#matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "#matplotlib.rcParams['figure.facecolor'] = '#00000000'\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, dataset1, dataset2):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dataset1), len(self.dataset2))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample1 = self.dataset1[idx]\n",
    "        sample2 = self.dataset2[idx]\n",
    "        return {'dim': sample1, 'target': sample2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "900\n",
      "Training set size: 900\n",
      "Validation set size: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the number of samples and the number of instances\n",
    "num_samples = 100\n",
    "num_instances = 1000\n",
    "\n",
    "# Generate random values for x, y, z between 0 and 1\n",
    "x = torch.rand(num_instances, num_samples)\n",
    "y = torch.rand(num_instances, num_samples)\n",
    "z = torch.rand(num_instances, num_samples)\n",
    "\n",
    "# Generate random values for target between -1000 and 1000\n",
    "target = torch.randint(-1000, 1001, (num_instances, num_samples))\n",
    "\n",
    "# Combine x, y, z, and target into a single tensor for each instance\n",
    "dim = torch.stack((x, y, z), dim=2)\n",
    "\n",
    "dataset = CombinedDataset(dim, target)\n",
    "\n",
    "val_size = num_instances//10\n",
    "train_size = num_instances - val_size\n",
    "print(val_size)\n",
    "print(train_size)\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)\n",
    "print(f\"Training set size: {len(train_ds)}\")\n",
    "print(f\"Validation set size: {len(val_ds)}\")\n",
    "batch_size=20\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=0, pin_memory=True)\n",
    "#print(f\"Training dataloadershape: {train_loader.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100, 3]) torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    data1 = batch['dim']\n",
    "    data2 = batch['target']\n",
    "    print(data1.shape, data2.shape)\n",
    "    data1 = to_device(data1, device)\n",
    "    data2 = to_device(data2, device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
